{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T21:33:33.122345Z",
     "start_time": "2024-03-30T21:33:33.080441Z"
    }
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ejemplo de predicción de modelo usando Redis\n",
    "\n",
    "Este notebook muestra cómo obtener predicciones de un modelo que produce predicciones en lotes. Las predicciones se cargaron en Redis. \n",
    "\n",
    "En este notebook, recuperamos las predicciones del modelo almacenadas en Redis. Los datos deben ser leídos, convertidos a cadenas y luego hasheados. Con este enfoque, podemos verificar si los datos existen en Redis y recuperar la predicción correspondiente. En caso de que los datos no existan, asignamos un valor de cero. Esta estrategia simula cómo podría comportarse un servicio en producción ante casos no contemplados.\n",
    "\n",
    "La ventaja de utilizar Redis en este contexto radica en su capacidad para almacenar datos de forma eficiente en memoria, lo que permite un acceso rápido a las predicciones previamente calculadas. Además, Redis ofrece funcionalidades de almacenamiento en caché y persistencia de datos, lo que garantiza la disponibilidad y la integridad de las predicciones incluso en entornos de producción de alta demanda."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ed44313a5cbc9d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Conectamos al servidor redis (correr el docker compose previamente, sino no funcionará)\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T21:33:33.125531Z",
     "start_time": "2024-03-30T21:33:33.123650Z"
    }
   },
   "id": "8764fb622fb44556",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Obtención de datos para prueba\n",
    "test_values = [\n",
    "    [4.9, 3.0, 1.4, 0.2],\n",
    "    [6.2, 2.9, 4.3, 1.3],\n",
    "    [5.7, 2.9, 4.2, 1.3],\n",
    "    [4.7, 3.2, 1.3, 0.2],\n",
    "    [4.6, 3.4, 1.4, 0.3],\n",
    "    [6.3, 3.4, 5.6, 2.4],\n",
    "    [5.7, 2.9, 4.2, 1.3],\n",
    "    [6.9, 3.1, 5.4, 2.1],\n",
    "    [0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "# Conversión de valores a cadenas y hash\n",
    "# Esto debería implementarse en el pipeline. Dado que los números de punto flotante pueden \n",
    "# presentar problemas debido a pequeñas variaciones, se podría considerar redondearlos.\n",
    "string_values = [' '.join(map(str, sublist)) for sublist in test_values]\n",
    "hashed_values = [hashlib.sha256(substring.encode()).hexdigest() for substring in string_values]  \n",
    "\n",
    "# Obtención de las salidas del modelo desde Redis\n",
    "# Estas salidas ya fueron procesadas en el pasado, por lo que consultamos Redis para obtenerlas.\n",
    "model_output = [r.get(hash_key) for hash_key in hashed_values]\n",
    "\n",
    "# Reemplazo de valores nulos con un valor predeterminado\n",
    "# Esto es necesario porque, en caso de una nueva entrada que el modelo no haya visto durante \n",
    "# el procesamiento por lotes, necesitamos proporcionar una salida. Esta entrada podría ser\n",
    "# encolada para su posterior procesamiento en lotes.\n",
    "model_output = [value if value is not None else 0 for value in model_output]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T21:33:33.136889Z",
     "start_time": "2024-03-30T21:33:33.126462Z"
    }
   },
   "id": "d2a7ec0e76ab869e",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos la salida del modelo para diferentes entradas:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cc50fadce217faa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la entrada: [4.9, 3.0, 1.4, 0.2]\n",
      "El modelo predice que: 0\n",
      "Para la entrada: [6.2, 2.9, 4.3, 1.3]\n",
      "El modelo predice que: 1\n",
      "Para la entrada: [5.7, 2.9, 4.2, 1.3]\n",
      "El modelo predice que: 1\n",
      "Para la entrada: [4.7, 3.2, 1.3, 0.2]\n",
      "El modelo predice que: 0\n",
      "Para la entrada: [4.6, 3.4, 1.4, 0.3]\n",
      "El modelo predice que: 0\n",
      "Para la entrada: [6.3, 3.4, 5.6, 2.4]\n",
      "El modelo predice que: 2\n",
      "Para la entrada: [5.7, 2.9, 4.2, 1.3]\n",
      "El modelo predice que: 1\n",
      "Para la entrada: [6.9, 3.1, 5.4, 2.1]\n",
      "El modelo predice que: 2\n",
      "Para la entrada: [0, 0, 0, 0]\n",
      "El modelo predice que: 0\n"
     ]
    }
   ],
   "source": [
    "for index, test_value in enumerate(test_values):\n",
    "    print(f\"Para la entrada: {test_value}\")\n",
    "    \n",
    "    print(f\"El modelo predice que: {model_output[index]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T21:33:33.140444Z",
     "start_time": "2024-03-30T21:33:33.138230Z"
    }
   },
   "id": "db0ccdbdf0cfde4a",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
